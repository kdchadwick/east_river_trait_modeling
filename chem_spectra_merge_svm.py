# -*- coding: utf-8 -*-
"""Chem Spectra Merge_SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YIQf6cCDbuiF_ZZyTJaSanhTd0xA2ZGK
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import matplotlib.gridspec as gridspec
import scipy
from scipy import stats
from sklearn.manifold import TSNE
import warnings
warnings.filterwarnings('ignore')
import argparse
import subprocess

from sklearn.svm import SVC, SVR
from sklearn.preprocessing import StandardScaler
from scipy.signal import savgol_filter
import pickle

import logging
import sys


parser = argparse.ArgumentParser('Run specific east-river trait submodels')
parser.add_argument('output_directory',type=str)
parser.add_argument('base_settings_file',type=str)
parser.add_argument('-wavelength_file',default='neon_wavelengths.txt')
parser.add_argument('-shade_type', type=str, choices=['dsm','tch','both','none'], default=None)
#parser.add_argument('-product', nargs='+', required=True, choices=['combined_csv', 'conifer', 'traits', 'all'])
parser.add_argument('-chem_file',default='/Users/kdchadwick/Google Drive File Stream/My Drive/CB_share/NEON/site_info/PLSR_FoliarResults_noBen.csv')
parser.add_argument('-spectra_file',default='/Users/kdchadwick/Google Drive File Stream/My Drive/CB_share/NEON/site_info/extraction_output_centroid_extended.csv')
parser.add_argument('-bn','--brightness_normalize', type=str, default='True')
parser.add_argument('-chem_names', nargs='+')
parser.add_argument('-spectral_smoothing', choices=['sg','none','2band','3band'], type=str, default='none')
parser.add_argument('-n_test_folds', default=10, type=int)
parser.add_argument('-n_folds_to_run', default=1, type=int)

parser.add_argument('-ndvi_min', default=0.5, type=float)

parser.add_argument('-plsr_ensemble_code_dir', default='/Users/kdchadwick/Documents/Github/crown_based_ensembling', type=str)

#parser.add_argument('-bb_file','--bad_bands_file', type=str)
#parser.add_argument('-chem_transforms',choices=['None','log','sqrt'],default='None')
#parser.add_argument('-ndvi_max', default=1, type=float)
#parser.add_argument('-min_pixel_per_crown', default=1, type=int)
#parser.add_argument('-max_components', default=13, type=int)
#parser.add_argument('-iterations', default=50, type=int)
#parser.add_argument('-iteration_fraction', default=0.25, type=float)
#parser.add_argument('-iteration_holdout_fraction', default=0.15, type=float)

args = parser.parse_args()
if args.brightness_normalize.lower() == 'true':
    args.brightness_normalize = True
else:
    args.brightness_normalize = False

assert args.n_folds_to_run <= args.n_test_folds, 'n_folds_to_run <= n_test_folds'


assert os.path.isdir(args.output_directory) is False, 'output directory already exists'
subprocess.call('mkdir ' + os.path.join(args.output_directory), shell=True)

logging.basicConfig(filename=os.path.join(args.output_directory,'log_file.txt'), level='INFO')

sys.path.append(args.plsr_ensemble_code_dir)
import read_settings_file
settings_file = read_settings_file.settings(args.base_settings_file)


def find_nearest(array_like, v):
    index = np.argmin(np.abs(np.array(array_like) - v))
    return index

plt.rcParams.update({'font.size': 20})
plt.rcParams['font.family']= "serif"
plt.rcParams['font.serif']= "Times New Roman"
plt.rcParams['axes.grid']=True
plt.rcParams['axes.axisbelow']=True
plt.rcParams['axes.labelpad']=6

#For jupyter notebooks
CN = pd.read_csv(args.chem_file)
extract = pd.read_csv(args.spectra_file)



#saving column names
headerCN = list(CN)
headerSpec = list(extract) # Reflectance bands start at 18 (17 in zero base)
#logging.info(headerSpec)

#removing shaded pixels
if args.shade_type == 'dsm':
    extract=extract.loc[extract['ered_B_1']==1]
elif args.shade_type == 'tch':
    extract=extract.loc[extract['_tch_B_1']==1]
elif args.shade_type == 'both':
    extract=extract.loc[(extract['_tch_B_1']==1) & (extract['ered_B_1'] == 1)]
elif args.shade_type == 'none':
    extract=extract.loc[extract['_tch_B_1'] != -9999]

#calculating NDVI using bands 54 and 96 for non-meadow sites 
NDVI = (np.array(extract["refl_B_96"])-np.array(extract["refl_B_54"]))/(np.array(extract["refl_B_96"])+np.array(extract["refl_B_54"]))
NDVImask = NDVI < args.ndvi_min
extract = extract.drop(extract[NDVImask].index)

CNmeadows = CN.loc[CN['Site_Veg']=='Meadow']
CNconifer = CN.loc[CN['Needles']==True]
CNbroadleaf = CN.loc[(CN['Needles']!=True) &(CN['Site_Veg']!='Meadow')]

np.random.seed(6)

fraction_sets = [1./float(args.n_test_folds) for i in range(args.n_test_folds)]

fraction_sets = []
for i in range(args.n_test_folds):
    fraction_sets.append(1./float(args.n_test_folds))

CalValM=np.random.choice(list(range(args.n_test_folds)), size=(CNmeadows.shape[0],), p=fraction_sets)
CalValC=np.random.choice(list(range(args.n_test_folds)), size=(CNconifer.shape[0],), p=fraction_sets)
CalValB=np.random.choice(list(range(args.n_test_folds)), size=(CNbroadleaf.shape[0],), p=fraction_sets)

CNmeadows['CalVal'] = CalValM
CNconifer['CalVal'] = CalValC
CNbroadleaf['CalVal'] = CalValB

#Merging chem data with the correct extraction data based on the
conifers = pd.merge(CNconifer,extract,how='inner', right_on = ['ID'], left_on=['SampleSiteID'])
meadows = pd.merge(CNmeadows,extract,how='inner', right_on = ['ID'], left_on=['SampleSiteID'])
broadleaf = pd.merge(CNbroadleaf,extract,how='inner', right_on = ['ID'], left_on=['SampleSiteID'])

# Concatenating data for different subset exports
noneedles = meadows.append(broadleaf)

# first column of reflectance data
rfdat = list(extract).index(settings_file.get_setting('band preface') + '1')

#defining wavelengths 
wv = np.genfromtxt(args.wavelength_file)
bad_bands = []
good_band_ranges = []

bad_band_ranges = [[0,425], [1345, 1410], [1805, 2020], [2470, 2700]]
for _bbr in range(len(bad_band_ranges)):
    bad_band_ranges[_bbr] = [find_nearest(wv,x) for x in bad_band_ranges[_bbr]]
    if (_bbr > 0):
        good_band_ranges.append([bad_band_ranges[_bbr-1][1], bad_band_ranges[_bbr][0]])

    for n in range(bad_band_ranges[_bbr][0], bad_band_ranges[_bbr][1]):
        bad_bands.append(n)
bad_bands.append(len(wv)-1)

good_bands = np.array([x for x in range(0,426) if x not in bad_bands])

all_band_indices = (np.array(good_bands)+rfdat).tolist()
all_band_indices.extend((np.array(bad_bands)+rfdat).tolist())
all_band_indices = np.sort(all_band_indices)

#extracting needle and non-needle samples
conifer_spectra=np.array(conifers[np.array(headerSpec)[all_band_indices]])
conifer_spectra[:,bad_bands]=np.nan

noneedles_spectra=np.array(noneedles[np.array(headerSpec)[all_band_indices]])
noneedles_spectra[:,bad_bands]=np.nan

spectra_sets = [conifer_spectra, noneedles_spectra]
color_sets = ['royalblue','darkorange']
names_sets = ['Conifer', 'Broadleaf']

conifer_crown=np.array(conifers["SampleSiteCode"])
noneedles_crown = np.array(noneedles["SampleSiteCode"])
crown_sets = [conifer_crown, noneedles_crown]

#####   Spectral smoothing #####
if (args.spectral_smoothing == '2band' or args.spectral_smoothing == '3band'):
    average_interval = 2
    if args.spectral_smoothing == '3band':
       average_interval = 3
    for _s in range(len(spectra_sets)):
        spectra = spectra_sets[_s]
        av_spec = [spectra[:,::average_interval]]
        if _s == 0:
            smoothed_spectra_wavelengths = 1 / float(average_interval) * wv[::average_interval]
        for _i in range(1,average_interval):
            av_spec.append(spectra[:,_i::average_interval])
            if _s == 0:
                smoothed_spectra_wavelengths += 1 / float(average_interval) * wv[_i::average_interval]

        av_spec = np.stack(av_spec)
        av_spec = np.nanmean(av_spec,axis=0)
        spectra_sets[_s] = av_spec
        if (_s == 0):
            wv = smoothed_spectra_wavelengths

elif (args.spectral_smoothing == 'sg'):
    for _s in range(len(spectra_sets)):
        spectra = spectra_sets[_s]
        for _gbr in range(len(good_band_ranges)):
            spectra[:,good_band_ranges[_gbr][0]:good_band_ranges[_gbr][1]] = \
                savgol_filter(spectra[:,good_band_ranges[_gbr][0]:good_band_ranges[_gbr][1]], window_length=5, polyorder=3, axis=1)
        spectra_sets[_s] = spectra

bad_bands = np.where(np.any(np.isnan(spectra_sets[0]), axis=0))[0].tolist()



if args.brightness_normalize:
    for _s in range(len(spectra_sets)):
        spectra = spectra_sets[_s]
        spectra = spectra / np.sqrt(np.nanmean(np.power(spectra,2),axis=1))[:,np.newaxis]
        spectra_sets[_s] = spectra

############### Rebuild dataframes for export  ##############
export_dataframes = [conifers.copy(), noneedles.copy()]
for _s in range(len(spectra_sets)):
    for b in range(spectra_sets[_s].shape[1] + 1, 427):
        export_dataframes[_s]=export_dataframes[_s].drop('refl_B_{}'.format(b), axis=1)
    for b in range(spectra_sets[_s].shape[1]):
        export_dataframes[_s]['refl_B_{}'.format(b + 1)]= spectra_sets[_s][:, b]



conifers_df_export = export_dataframes[0]
noneedles_df_export = export_dataframes[1]
aggregated_df_export=conifers_df_export.append(noneedles_df_export)

# Export to output files
subprocess.call('mkdir ' + os.path.join(args.output_directory,'data'), shell=True)
output_df_set_files = []
output_df_set_files.append(os.path.join(args.output_directory,'data','extraction_chem.csv'))
output_df_set_files.append(os.path.join(args.output_directory,'data','extraction_chem_needles.csv'))
output_df_set_files.append(os.path.join(args.output_directory,'data','extraction_chem_noneedles.csv'))

aggregated_df_export.to_csv(output_df_set_files[0], index=False, sep=',')
conifers_df_export.to_csv(output_df_set_files[1], index=False, sep=',')
noneedles_df_export.to_csv(output_df_set_files[2], index=False, sep=',')

figure_base_dir = os.path.join(args.output_directory,'figures')
subprocess.call('mkdir ' + figure_base_dir, shell=True)
figure_export_settings = {'dpi': 200, 'bbox_inches': 'tight'}

fig = plt.figure(figsize=(8,5), constrained_layout=True)
for _s in range(len(spectra_sets)):
    spectra = spectra_sets[_s]
    plt.plot(wv, np.nanmean(spectra, axis=0) / 100, c=color_sets[_s], linewidth = 2)
    plt.fill_between(wv, np.nanmean(spectra, axis=0) / 100 - np.nanstd(spectra, axis=0) / 100, np.nanmean(spectra, axis=0) / 100 + np.nanstd(spectra, axis=0) / 100, alpha=.35, facecolor=color_sets[_s])
    
plt.legend(['Needle', 'Non-Needle'])
plt.ylabel('Reflectance (%)')
if args.brightness_normalize:
    plt.ylabel('Brightness Norm. Reflectance')
else:
    plt.ylabel('Reflectance (%)')
plt.xlabel('Wavelength (nm)')

plt.savefig(os.path.join(figure_base_dir,'class_spectra.png'), **figure_export_settings)
del fig



###########  Now set up and run SVM to discrimitate conifers
all_spectra = np.vstack([x for x in spectra_sets])
all_crowns = np.vstack([x.reshape(-1,1) for x in crown_sets]).flatten()

is_conifer = np.zeros(all_spectra.shape[0]).astype(bool)
is_conifer[:conifer_spectra.shape[0]] = True

all_spectra = all_spectra[:,np.all(np.isnan(all_spectra) == False, axis=0)]

un_crowns = np.unique(all_crowns)

train_crowns = un_crowns[np.random.permutation(len(un_crowns))[:int(len(un_crowns)*0.9)]]
train = np.zeros(all_spectra.shape[0]).astype(bool)
for _c in range(len(train_crowns)):
  train[all_crowns == train_crowns[_c]] = True

#scaler = StandardScaler()
#scaler.fit(all_spectra[train,:])
#all_spectra = scaler.transform(all_spectra)

model = SVC(gamma='auto',kernel='poly',degree=3,probability=True)
model.fit(all_spectra[train,:], is_conifer.astype(int)[train])

subset = np.logical_not(train)
spectral_sep = model.predict(all_spectra).astype(bool)

logging.info('Reflectance Model...BN used: '.format(args.brightness_normalize))
logging.info('Correct conifers: {}'.format(np.sum(np.logical_and(is_conifer[subset], spectral_sep[subset])/np.sum(is_conifer[subset]))))
logging.info('Falsely IDd conifers: {}'.format(np.sum(np.logical_and(np.logical_not(is_conifer[subset]), spectral_sep[subset]))/np.sum(np.sum(is_conifer[subset]))))
logging.info('Missed Conifers: {}'.format(np.sum(np.logical_and(is_conifer[subset], np.logical_not(spectral_sep[subset]))/np.sum(is_conifer[subset]))))

fig = plt.figure(figsize=(10,4), constrained_layout=True)
ax = fig.add_axes([0,0,.55,.9])
for _s in range(len(spectra_sets)):
    spectra = spectra_sets[_s]
    plt.plot(wv,np.nanmean(spectra,axis=0), c=color_sets[_s], linewidth = 3)
    plt.fill_between(wv,np.nanmean(spectra,axis=0) - np.nanstd(spectra,axis=0),np.nanmean(spectra,axis=0) + np.nanstd(spectra,axis=0), alpha=.35, facecolor=color_sets[_s])
    
plt.legend(['Needle', 'Non-Needle'])
plt.xlabel('Wavelength (nm)')
if args.brightness_normalize:
    plt.ylabel('Brightness Norm. Reflectance')
else:
    plt.ylabel('Reflectance (%)')

ax = fig.add_axes([0.73,0,.3,.9])
probabilities = model.predict_proba(all_spectra[subset])
plt.hist((1-probabilities[is_conifer[subset]==True,0]), facecolor='royalblue', alpha=0.5, range=(0,1), bins=15)
plt.hist((1-probabilities[is_conifer[subset]==False,0]), facecolor='darkorange', alpha=0.5, range=(0,1), bins=15)
plt.ylabel('Pixel Count')
plt.xlabel('Conifer Probability')
plt.savefig(os.path.join(figure_base_dir,'svm_performance.png'), **figure_export_settings)
del fig

model_base_dir = os.path.join(args.output_directory,'models')
subprocess.call('mkdir ' + model_base_dir, shell=True)

model.fit(all_spectra, is_conifer.astype(int))
pickle.dump(model,open(os.path.join(model_base_dir,'svm_model_alldata'),'wb'))



#X = full[headerSpec].values.astype(float)
#y = full['N_weight_percent'].values.astype(float).reshape(-1,1)
#
#sc_x = StandardScaler()
#sc_y = StandardScaler()
#X = sc_x.fit_transform(X)
#y = sc_y.fit_transform(y)
#
#regressor = SVR(kernel = 'rbf')
#regressor.fit(X,y)


starting_dir = os.getcwd()
output_df_set_files.pop(1)
output_df_set_files.pop(1)
for output_df_set in output_df_set_files:

    chem_output_dir = os.path.splitext(os.path.basename(output_df_set))[0]
    chem_output_dir = chem_output_dir.split('_')[-1]
    chem_output_dir = os.path.join(args.output_directory,chem_output_dir)
    subprocess.call('mkdir ' + chem_output_dir, shell=True)
    for fold in range(args.n_folds_to_run):

        bad_bands_str = ''
        for n in bad_bands:
            bad_bands_str += str(n+1) + ','
        settings_file.settings_obj['Spectral']['bad bands(1-based)'] = bad_bands_str[:-1]

        bn_norm_str = 'False'
        settings_file.settings_obj['Spectral']['brightness normalize'] = bn_norm_str

        settings_file.settings_obj['Data']['csv file'] = os.path.join(os.getcwd(),output_df_set)

        settings_file.settings_obj['Data']['test set value'] = str(fold)

        if args.spectral_smoothing == '2band':
            settings_file.settings_obj['Spectral']['max band'] = '213'
            settings_file.settings_obj['Spectral']['wavelength interval(nm)'] = '10'
        elif args.spectral_smoothing == '3band':
            settings_file.settings_obj['Spectral']['max band'] = '142'
            settings_file.settings_obj['Spectral']['wavelength interval(nm)'] = '15'

        fold_output_dir = os.path.join(chem_output_dir,'fold_' + str(fold))
        subprocess.call('mkdir ' + fold_output_dir,shell=True)

        settings_file.settings_obj['General']['version name'] = fold_output_dir.replace('/','_')

        output_sf = os.path.join(os.getcwd(), os.path.join(fold_output_dir,'settings_file.txt'))
        with open(output_sf, 'w') as configfile:
            settings_file.settings_obj.write(configfile)

        os.chdir(fold_output_dir)
        cmd_str = 'python {} {}'.format(os.path.join(args.plsr_ensemble_code_dir,'ensemble_plsr.py'),output_sf)
        logging.info('calling:\n{}'.format(cmd_str))
        #subprocess.call(cmd_str,shell=True)
        os.chdir(starting_dir)
